import random
import cv2
import numpy as np
import lmdb
import torch.nn.functional as F
from pdb import set_trace as st
from skimage.feature import local_binary_pattern
import json
from tqdm import tqdm
from PIL import Image

import os
import torch
from torch.utils.data import Dataset, DataLoader
from .transforms import create_train_transforms, ComposedTransforms, JPEG_Compression, pixel_blend_mix, freq_blend_mix, apply_resize, create_val_transforms, create_val_transforms_2

class RealFakeDataset(Dataset):
    def __init__(self, args, **kwargs):
        self.args = args
        self._length = 0
        # 输入的配置文件包括
        #   dataset 的内容 和 train/val/test 当中的dataset内容        
        for k, v in kwargs.items():
            setattr(self, k, v)

        self._initial_env()
        if self.args.distributed and self.args.local_rank==0 or not self.args.distributed:
            self._display_infos()

    def _initial_env(self):
        self.items = []
        self.dataset_sources = {}

        # Load JPEG quality factor mapping for aligned compression
        with open(self.quality_json, "rb") as file:
            self.real_quality_factor_mapping = json.load(file)

        # Parse comma-separated paths
        real_data_paths = [path.strip() for path in self.real_data_path.split(',')]
        vae_rec_data_paths = [path.strip() for path in self.vae_rec_data_path.split(',')]

        # Validate that we have the same number of real and VAE paths
        if len(real_data_paths) != len(vae_rec_data_paths):
            raise ValueError(f"Number of real_data_path ({len(real_data_paths)}) must match "
                           f"number of vae_rec_data_path ({len(vae_rec_data_paths)})")

        # Load datasets from all path pairs
        for i, (real_path, vae_path) in enumerate(zip(real_data_paths, vae_rec_data_paths)):
            print(f"Loading dataset {i+1}/{len(real_data_paths)}: {real_path} -> {vae_path}")
            
            # Create source name based on index
            source_name = f"dataset_{i+1}"
            
            samples = self._load_dataset(
                real_data_path=real_path,
                vae_path=vae_path,
                source_name=source_name
            )
            self.items.extend(samples)
        # Print dataset statistics
        for source, count in self.dataset_sources.items():
            print(f"Loaded {count} samples from {source}")
        
        # Shuffle dataset for randomness in sampling
        random.shuffle(self.items)
        
        # Configure JPEG quality settings if enabled
        if self.args.transform.jpeg_quality:
            print(f'Add random JPEG compression into transform: [{self.args.transform.jpeg_quality}, 100]')
   
        # Create separate transformation pipelines for PNG and JPEG images
        # For PNG images: Include JPEG compression to simulate real-world artifacts
        transform_list_png = create_train_transforms(args=self.args.transform, jpeg_quality=self.args.transform.jpeg_quality)
        self.transform_png = ComposedTransforms(transform_list_png)
        
        # For JPEG images: Skip additional JPEG compression (already have artifacts)
        transform_list_jpeg = create_train_transforms(args=self.args.transform, jpeg_quality=None)
        self.transform_jpeg = ComposedTransforms(transform_list_jpeg)
        
        self.transform_list_val = create_val_transforms(self.args.transform)
        self.transform_val = ComposedTransforms(self.transform_list_val)

        # Set patch shuffle parameters (for potential future use)
        self.patch_size = getattr(self.args, 'patch_size', 14)

        # Set probabilities for various augmentations
        self.p_jpeg_fake = self.args.transform.p_jpeg_fake
        self.p_png_real = self.args.transform.p_png_real
        self.p_freqmix = self.args.transform.p_freqmix
        
        self.color_space = [f.strip() for f in self.args.transform.mix_color_space.split(',')]

        self._length = len(self.items)

    def _load_dataset(self, real_data_path, vae_path, source_name):
        """
        Helper method to load dataset samples from a list of real images and corresponding
        fake images generated by different VAE models.
        
        Args:
            real_data_path: Path to the real images
            vae_path: Path to the vae images
            source_name: Name of this data source for tracking/analysis
            
        Returns:
            List of samples loaded from this data source
        """
        samples = []
        
        # Initialize counter for this source
        self.dataset_sources[source_name] = 0
        
        # Get real image paths
        real_list = self._get_list(real_data_path)
        real_list.sort()

        # Construct the complete dataset
        for real_path in tqdm(real_list, desc=f"Loading {source_name}..."):
            # Create a data sample with real path and corresponding fake paths
            sample = {
                'real_path': real_path,
                'fake_path': None,
                'source': source_name,  # Track which dataset this sample came from
                'format': 'jpeg' if real_path.lower().endswith('.jpg') or real_path.lower().endswith('.jpeg') else 'png',
                'jpeg_quality': self.real_quality_factor_mapping.get(os.path.basename(real_path), 100)
            }

            # Extract base filename for matching with fake images
            basename_real_path = os.path.basename(real_path)
            basename_real_path_without_suffix = os.path.splitext(basename_real_path)[0] 
            basename_fake_path = basename_real_path_without_suffix + '.png'
            
            vae_rec_path = os.path.join(vae_path, basename_fake_path)
            if not os.path.exists(vae_rec_path):
                print(f"Missing file: {vae_rec_path}")
                raise ValueError(f'{vae_rec_path} does not exist!')
            else:
                sample['fake_path'] = vae_rec_path
                samples.append(sample)
                self.dataset_sources[source_name] += 1
            
        return samples

    def _get_list(self, path, must_contain=''):
        image_list = self._recursively_read(path, must_contain)
        return image_list

    def _recursively_read(self, rootdir, must_contain, exts=["png", "jpg", "JPEG", "jpeg"]):
        out = [] 
        for r, d, f in os.walk(rootdir, followlinks=True):
            for file in f:
                if (file.split('.')[1].lower() in exts)  and  (must_contain in os.path.join(r, file)):
                    out.append(os.path.join(r, file))
        return out

    def _display_infos(self):
        print(f'=> Dataset {self.__class__.__name__} loaded')
        print(f'=> Split Training')
        print(f'=> Total number of items: {self._length}')

    def __len__(self):
        return self._length

    def _select_random_freqmix_patch_size(self):
        """
        Randomly select a patch size for frequency mixing that satisfies:
        1. patch_size % 14 == 0 (divisible by 14)
        2. self.opt.cropSize % patch_size == 0 (patch_size is a factor of cropSize)  
        3. patch_size > self.opt.cropSize * self.opt.freqmix_patch_ratio (above minimum threshold)
        
        Returns:
            Random valid patch size
        """
        crop_size = self.args.transform.crop_size
        min_patch_size = crop_size * self.args.transform.freqmix_patch_ratio
        
        valid_patch_sizes = []
        
        # Check multiples of 14 up to crop_size
        patch_size = 14
        while patch_size <= crop_size:
            if crop_size % patch_size == 0 and patch_size > min_patch_size:
                valid_patch_sizes.append(patch_size)
            patch_size += 14
        
        if not valid_patch_sizes:
            # Fallback: return the smallest valid multiple of 14 that's a divisor of crop_size
            patch_size = 14
            while patch_size <= crop_size:
                if crop_size % patch_size == 0:
                    return patch_size
                patch_size += 14
            # If even that fails, return 14 (though this should be very rare)
            return 14
        
        return random.choice(valid_patch_sizes)

    def __getitem__(self, index):
        # get image for dino
        # Available resampling methods for resizing
        resampling_methods = [
            Image.NEAREST,   # Nearest neighbor - fastest, lowest quality
            Image.BOX,       # Box sampling - fast, low quality
            Image.BILINEAR,  # Bilinear - balanced speed/quality
            Image.HAMMING,   # Hamming - improved bilinear
            Image.BICUBIC,   # Bicubic - higher quality
            Image.LANCZOS,   # Lanczos - highest quality, slowest
        ]
        # Create image dictionary to hold all versions
        img_dict = {
            'real': None,
            'fake': None,
            'real_resized': [],
            'fake_resized': [],
        }
        
        # Get sample data
        sample = self.items[index]
        
        # Determine actual file format and use it as a hint for mode selection
        actual_format = sample['format'] 
        real_img_path = sample['real_path']
        
        # Load real image    
        real_img = Image.open(sample['real_path']).convert("RGB")
        img_dict['real'] = real_img
        
        # Randomly select one fake image path with error handling
        fake_path = sample['fake_path']
        fake_img = Image.open(fake_path).convert("RGB")
        
        # print(f"real_path ({self.args.local_rank}): {sample['real_path']}")

        if random.random() < self.p_jpeg_fake:
            jpeg_quality_factor = int(sample['jpeg_quality'])
            # For datasets other than primary MSCOCO, use random quality
            if sample.get('source') != 'dataset_1':  # Assuming first dataset is primary MSCOCO
                jpeg_quality_factor = random.randint(85, 100)
            fake_img = JPEG_Compression(fake_img, jpeg_quality_factor)
        
        # Create a list of blending operations to perform
        blending_operations = []
        # Add pixel blending if it passes the probability check
        if self.args.transform.p_pixelmix > 0 and random.random() < self.args.transform.p_pixelmix:
            blending_operations.append('pixel')

        # Add frequency blending if it passes the probability check
        if self.args.transform.p_freqmix > 0 and random.random() < self.args.transform.p_freqmix:
            blending_operations.append('frequency')

        # Shuffle the operations to randomize their order
        if blending_operations:
            random.shuffle(blending_operations)
            
            # Apply operations in the shuffled order
            for operation in blending_operations:
                if operation == 'pixel':
                    # Apply pixel blending
                    resize_method = random.choice(resampling_methods)
                    fake_img_resized = fake_img.resize(real_img.size, resize_method)
                    fake_img = pixel_blend_mix(
                        real_img=real_img, 
                        fake_img=fake_img_resized, 
                        ratios=[0, self.args.transform.r_pixelmix],
                        color_space=random.choice(self.color_space),
                        mode=self.args.transform.meth_pixelmix,
                    )

                elif operation == 'frequency':
                    fake_img = freq_blend_mix(
                        real_img=real_img, 
                        fake_img=fake_img, 
                        ratios=[0, self.args.transform.r_freqmix], 
                        color_space=random.choice(self.color_space),
                        mode=self.args.transform.meth_freqmix,  # Randomly select frequency blending mode
                        patch=self._select_random_freqmix_patch_size()
                    )

        # Store the final fake image in the dictionary
        img_dict['fake'] = fake_img
            
        # Select random resize factors between the range bounds
        down_resize_factor = random.uniform(self.args.transform.down_resize_factors, 1.0)
        upper_resize_factor = random.uniform(1.0, self.args.transform.upper_resize_factors)
        # Select two random methods without replacement
        resize_methods = random.sample(resampling_methods, 2)

        # Apply resizing with selected factors and methods
        for resize_factor, resize_method in zip([down_resize_factor, upper_resize_factor], resize_methods):
            # Create resized versions with the SAME resize factor and method for both real and fake
            real_resized = apply_resize(real_img, resize_factor, resize_method)
            fake_resized = apply_resize(fake_img, resize_factor, resize_method)
        
            img_dict['real_resized'].append(real_resized)
            img_dict['fake_resized'].append(fake_resized)
        
        # Apply transforms to all images based on the selected mode
        # JPEG images use the JPEG transform pipeline (no additional compression)
        # PNG images use the PNG transform pipeline (with potential compression)
        transformed_dict = self.transform_jpeg(img_dict) if actual_format == 'jpeg' else self.transform_png(img_dict)
        
        # transformed_dict = self.transform_val(img_dict)
        
        # Add source information to help with analysis
        transformed_dict['source'] = sample['source']

        return transformed_dict


class RealFakeDataset_Val(Dataset):
    def __init__(self, args, split='val', **kwargs):
        self.args = args
        self.split = split
        self._length = 0
        # 输入的配置文件包括
        #   dataset 的内容 和 train/val/test 当中的dataset内容        
        for k, v in kwargs.items():
            setattr(self, k, v)

        self._initial_env()
        if self.args.distributed and self.args.local_rank==0 or not self.args.distributed:
            self._display_infos()

    def _initial_env(self):
        self.items = []
        self.list_path = os.path.join(self.dataset_root, self.phase, self.list_path)

        if os.path.exists(self.list_path):
            self.items = open(self.list_path).readlines()
        else:
            raise ValueError(f'{self.list_path} does not exist!')
        
        # Fixed transform
        self.transform = create_val_transforms(self.args.transform)
        self.transform_2 = create_val_transforms_2(self.args.transform)
        
        self._length = len(self.items)

    def __len__(self):
        return self._length
    
    def _display_infos(self):
        print(f'=> Dataset {self.__class__.__name__} loaded')
        print(f'=> Split {self.split}')
        print(f'=> Total number of items: {self._length}')

    def __getitem__(self, index):
        # 加载原始数据
        item = self.items[index]
        img_path = os.path.join(self.dataset_root,self.phase,item.split(' ')[0])
        assert os.path.exists(img_path), f'{img_path} does not exist!'
        label_all = item.split(' ')[1] # X_X_X

        if label_all[0] == '0':
            label = 0
        else:
            label = 1
        try:
            image = Image.open(img_path).convert('RGB')
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        except:
            print(f'{img_path} is corrupted!')
        
        image_tensor = self.transform(image)
        result = self.transform_2(image=img)
        img = result['image']

        return image_tensor, label, img_path, img
    

def set_seed(SEED):
    if SEED:
        random.seed(SEED)
        np.random.seed(SEED)
        torch.manual_seed(SEED)
        torch.cuda.manual_seed(SEED)
        torch.cuda.manual_seed_all(SEED)
        torch.backends.cudnn.deterministic = True

if __name__ == '__main__':
    from omegaconf import OmegaConf
    args = OmegaConf.load('./config/ICCV_Workshop/train.yaml')
    args.dataset.name = 'RealFakeDataset'
    kwargs = getattr(args.dataset, args.dataset.name)
    args.local_rank = 0
    args.world_size = 1
    args.distributed = False
    args.num_workers = 0
    set_seed(1234)

    split = 'train'
    kwargs.update(args[split]['dataset'])

    train_dataset = RealFakeDataset(args, **kwargs)
    train_dataloader = DataLoader(train_dataset, batch_size=args.train.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=True, drop_last=True)
    for i, datas in enumerate(train_dataloader):
        for k,v in datas.items():
            print(v.shape) if type(v) is torch.Tensor else len(v)
            if type(v) is torch.Tensor:
                print(v.mean((1,2,3)))
                import torchvision as tv
                tv.utils.save_image(v, f'{k}.png', normalize=True)
            else:
                if isinstance(v, list):
                    for sub_v in v:
                        if type(sub_v) is torch.Tensor:
                            print(sub_v.mean((1,2,3)))
        break
    
    split = 'val'
    kwargs.update(args[split]['dataset'])
    train_dataset = RealFakeDataset_Val(args, split=split, **kwargs)
    train_dataloader = DataLoader(train_dataset, batch_size=args.train.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=True, drop_last=True)
    for i, datas in enumerate(train_dataloader):
        for data in datas:
            print(data.shape) if type(data) is torch.Tensor else len(data)
        import torchvision as tv
        tv.utils.save_image(datas[0], 'val_image_l1.png', normalize=True)
        # tv.utils.save_image(datas[1].unsqueeze(1), 'depth.png')
        break

    split = 'test'
    kwargs.update(args[split]['dataset'])
    train_dataset = RealFakeDataset_Val(args, split=split, **kwargs)
    train_dataloader = DataLoader(train_dataset, batch_size=args.train.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=True, drop_last=True)
    for i, datas in enumerate(train_dataloader):
        for data in datas:
            print(data.shape) if type(data) is torch.Tensor else len(data)
        import torchvision as tv
        tv.utils.save_image(datas[0], 'test_image_l1.png', normalize=True)
        # tv.utils.save_image(datas[1].unsqueeze(1), 'depth.png')
        break

    